{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml.feature import StopWordsRemover,RegexTokenizer, StringIndexer, CountVectorizer\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"PA3\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "traindataframe = spark.createDataFrame(df)\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "testdataframe = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "traindataframe = regexTokenizer.transform(traindataframe)\n",
    "testdataframe = regexTokenizer.transform(testdataframe)\n",
    "\n",
    "swremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filteredwords\")\n",
    "traindataframe = swremover.transform(traindataframe)\n",
    "testdataframe = swremover.transform(testdataframe)\n",
    "\n",
    "countvectorizer = CountVectorizer(inputCol=\"filteredwords\", outputCol=\"features\")\n",
    "countvectorizer = countvectorizer.fit(traindataframe)\n",
    "traindataframe = countvectorizer.transform(traindataframe)\n",
    "testdataframe = countvectorizer.transform(testdataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|            features|               genre|\n",
      "+--------+--------------------+--------------------+\n",
      "|23890098|(119399,[10,129,1...|['World cinema', ...|\n",
      "|31186339|(119399,[2,6,7,10...|['Action/Adventur...|\n",
      "|20663735|(119399,[1,3,8,10...|['Musical', 'Acti...|\n",
      "| 2231378|(119399,[7,9,12,1...|          ['Comedy']|\n",
      "|  595909|(119399,[2,8,9,14...|['Crime Fiction',...|\n",
      "| 5272176|(119399,[2,4,5,12...|['Action/Adventur...|\n",
      "| 1952976|(119399,[0,1,2,3,...|['Thriller', 'Dra...|\n",
      "|24225279|(119399,[0,1,2,5,...|           ['Drama']|\n",
      "| 2462689|(119399,[0,4,9,17...|['Black-and-white...|\n",
      "|20532852|(119399,[11,31,38...|['Animation', 'Sh...|\n",
      "|15401493|(119399,[1,3,4,7,...|          ['Comedy']|\n",
      "|18188932|(119399,[0,2,14,3...|['Crime Fiction',...|\n",
      "| 2940516|(119399,[4,5,15,1...|          ['Comedy']|\n",
      "| 1480747|(119399,[0,1,2,3,...|          ['Comedy']|\n",
      "|24448645|(119399,[0,8,54,7...|          ['Horror']|\n",
      "|15072401|(119399,[5,14,61,...|['Crime Fiction',...|\n",
      "| 4018288|(119399,[2,7,21,2...|           ['Drama']|\n",
      "| 4596602|(119399,[0,2,4,8,...|['Crime Fiction',...|\n",
      "|15224586|(119399,[1,2,4,10...|  ['Indie', 'Drama']|\n",
      "|15585766|(119399,[0,9,10,4...|           ['Drama']|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traindataframe.select('movie_id','features','genre').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|movie_id|            features|\n",
      "+--------+--------------------+\n",
      "| 1335380|(119399,[0,3,4,7,...|\n",
      "|29062594|(119399,[7,8,56,7...|\n",
      "| 9252321|(119399,[5,7,11,1...|\n",
      "|13455076|(119399,[0,66,81,...|\n",
      "|24165951|(119399,[18,379,4...|\n",
      "| 1925869|(119399,[0,1,2,3,...|\n",
      "|10799612|(119399,[0,4,6,8,...|\n",
      "|28238240|(119399,[15,21,19...|\n",
      "|17124781|(119399,[5,9,11,1...|\n",
      "|28207941|(119399,[49,56,21...|\n",
      "|19174305|(119399,[1,3,5,7,...|\n",
      "|18392317|(119399,[4,7,13,1...|\n",
      "|34420857|(119399,[3,6,10,1...|\n",
      "| 4039635|(119399,[0,1,4,17...|\n",
      "| 8034072|(119399,[2,3,8,10...|\n",
      "| 4016437|(119399,[0,2,3,6,...|\n",
      "| 1520023|(119399,[0,1,2,3,...|\n",
      "|24589422|(119399,[0,1,3,6,...|\n",
      "|35068740|(119399,[10,20,28...|\n",
      "|21132951|(119399,[0,3,5,8,...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testdataframe.select('movie_id','features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Drama',\n",
       " 1: 'Comedy',\n",
       " 2: 'Romance Film',\n",
       " 3: 'Thriller',\n",
       " 4: 'Action',\n",
       " 5: 'World cinema',\n",
       " 6: 'Crime Fiction',\n",
       " 7: 'Horror',\n",
       " 8: 'Black-and-white',\n",
       " 9: 'Indie',\n",
       " 10: 'Action/Adventure',\n",
       " 11: 'Adventure',\n",
       " 12: 'Family Film',\n",
       " 13: 'Short Film',\n",
       " 14: 'Romantic drama',\n",
       " 15: 'Animation',\n",
       " 16: 'Musical',\n",
       " 17: 'Science Fiction',\n",
       " 18: 'Mystery',\n",
       " 19: 'Romantic comedy'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = spark.read.load(\"./mapping.csv\", format=\"csv\",sep=\",\", inferschema=\"true\", header=\"true\")\n",
    "genre_map = mapping.select(\"_c0\", \"0\").rdd.collectAsMap()\n",
    "genre_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filteredwords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label0: integer (nullable = true)\n",
      " |-- label1: integer (nullable = true)\n",
      " |-- label2: integer (nullable = true)\n",
      " |-- label3: integer (nullable = true)\n",
      " |-- label4: integer (nullable = true)\n",
      " |-- label5: integer (nullable = true)\n",
      " |-- label6: integer (nullable = true)\n",
      " |-- label7: integer (nullable = true)\n",
      " |-- label8: integer (nullable = true)\n",
      " |-- label9: integer (nullable = true)\n",
      " |-- label10: integer (nullable = true)\n",
      " |-- label11: integer (nullable = true)\n",
      " |-- label12: integer (nullable = true)\n",
      " |-- label13: integer (nullable = true)\n",
      " |-- label14: integer (nullable = true)\n",
      " |-- label15: integer (nullable = true)\n",
      " |-- label16: integer (nullable = true)\n",
      " |-- label17: integer (nullable = true)\n",
      " |-- label18: integer (nullable = true)\n",
      " |-- label19: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "def generateLabels(row, i): \n",
    "    label = 0\n",
    "    for x in row[1:-1].split(\",\"):\n",
    "        if x.strip()[1:-1] == genre_map.get(i):\n",
    "            label = 1\n",
    "    return label\n",
    "udfFunc = F.udf(generateLabels, IntegerType())\n",
    "for i in range(len(genre_map)):    \n",
    "    traindataframe = traindataframe.withColumn(\"label\"+str(i), udfFunc(\"genre\",F.lit(i)))\n",
    "traindataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filteredwords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- predictions: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generateLabelCol(): \n",
    "    return \"\"\n",
    "udfFunc = F.udf(generateLabelCol, StringType())\n",
    "\n",
    "testdataframe = testdataframe.withColumn(\"predictions\", udfFunc())\n",
    "testdataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "# from pyspark.mllib.regression import LabeledPoint\n",
    "# from pyspark.mllib.linalg import Vector as MLLibVector, Vectors as MLLibVectors\n",
    "\n",
    "# def parsePoint(line):\n",
    "#     return LabeledPoint(line.label, MLLibVectors.fromML(line.features))\n",
    "# for i in range(len(genre_map)):\n",
    "#     print('classifying Genre '+str(i+1)+ \" : \"+genre_map.get(i))\n",
    "#     parsedData = traindataframe.selectExpr(\"label\"+str(i)+\" as label\", \"features\").rdd.map(parsePoint)\n",
    "#     model = LogisticRegressionWithLBFGS.train(parsedData)\n",
    "#     model.save(spark,'./Models/Part1/model'+str(i))\n",
    "#     labelsAndPreds = testdataframe.rdd.map(lambda p: (p.movie_id, model.predict(MLLibVectors.fromML(p.features))))\n",
    "#     label_map = labelsAndPreds.collectAsMap()\n",
    "#     def addLabel(m_id, row): \n",
    "#         row= row + str(label_map.get(m_id))+\" \"\n",
    "#         return row\n",
    "#     udfFunc = F.udf(addLabel, StringType())\n",
    "#     testdataframe = testdataframe.withColumn(\"predictions\", udfFunc(\"movie_id\",\"predictions\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying Genre 1 : Drama\n",
      "classifying Genre 2 : Comedy\n",
      "classifying Genre 3 : Romance Film\n",
      "classifying Genre 4 : Thriller\n",
      "classifying Genre 5 : Action\n",
      "classifying Genre 6 : World cinema\n",
      "classifying Genre 7 : Crime Fiction\n",
      "classifying Genre 8 : Horror\n",
      "classifying Genre 9 : Black-and-white\n",
      "classifying Genre 10 : Indie\n",
      "classifying Genre 11 : Action/Adventure\n",
      "classifying Genre 12 : Adventure\n",
      "classifying Genre 13 : Family Film\n",
      "classifying Genre 14 : Short Film\n",
      "classifying Genre 15 : Romantic drama\n",
      "classifying Genre 16 : Animation\n",
      "classifying Genre 17 : Musical\n",
      "classifying Genre 18 : Science Fiction\n",
      "classifying Genre 19 : Mystery\n",
      "classifying Genre 20 : Romantic comedy\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vector as MLLibVector, Vectors as MLLibVectors\n",
    "\n",
    "def parsePoint(line):\n",
    "    return LabeledPoint(line.label, MLLibVectors.fromML(line.features))\n",
    "for i in range(len(genre_map)):\n",
    "    print('classifying Genre '+str(i+1)+ \" : \"+genre_map.get(i))\n",
    "    model = LogisticRegressionModel.load(spark, './Models/Part1/model'+str(i))\n",
    "    labelsAndPreds = testdataframe.rdd.map(lambda p: (p.movie_id, model.predict(MLLibVectors.fromML(p.features))))\n",
    "    label_map = labelsAndPreds.collectAsMap()\n",
    "    def addLabel(m_id, row): \n",
    "        row= row + str(label_map.get(m_id))+\" \"\n",
    "        return row\n",
    "    udfFunc = F.udf(addLabel, StringType())\n",
    "    testdataframe = testdataframe.withColumn(\"predictions\", udfFunc(\"movie_id\",\"predictions\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------------------+\n",
      "|movie_id|predictions                             |\n",
      "+--------+----------------------------------------+\n",
      "|1335380 |1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 |\n",
      "|29062594|0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|9252321 |0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|13455076|0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|24165951|0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|1925869 |1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|10799612|1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|28238240|0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|17124781|0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 |\n",
      "|28207941|0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 |\n",
      "|19174305|0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|18392317|0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 |\n",
      "|34420857|0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|4039635 |0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|8034072 |1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 |\n",
      "|4016437 |1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|1520023 |1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 |\n",
      "|24589422|1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|35068740|0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "|21132951|0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 |\n",
      "+--------+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testdataframe.select('movie_id','predictions').show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataframe.select('movie_id','predictions').write.format(\"csv\").option(\"header\", \"true\").mode(\"append\").save(\"outputs/output1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
